{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mask RCNN With OpenCV DNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import argparse\n",
    "import numpy as np\n",
    "import os.path\n",
    "import sys\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "confThreshold = 0.5  # Confidence threshold\n",
    "maskThreshold = 0.3  # Mask threshold\n",
    "image_path = \"data/cars.jpg\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Draw the predicted bounding box, colorize and show the mask on the image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawBox(frame, classId, conf, left, top, right, bottom, classMask):\n",
    "    # Use OpenCV's cv2.rectangle to draw a bounding box.\n",
    "    cv.rectangle(frame, (left, top), (right, bottom), (241, 113, 23), 3)\n",
    "    \n",
    "    # get scale factor\n",
    "    scale = frame.shape[1]/(2*1080)\n",
    "    \n",
    "    # Get a label of class.\n",
    "    label = '%.2f' % conf\n",
    "    if classes:\n",
    "        assert(classId < len(classes))\n",
    "        label = '%s:%s' % (classes[classId], label)\n",
    "    \n",
    "    # Display the label at the top of the bounding box\n",
    "    labelSize, baseLine = cv.getTextSize(label, cv.FONT_HERSHEY_DUPLEX, scale, 1)\n",
    "    top = max(top, labelSize[1])\n",
    "    cv.rectangle(frame, (left, top - round(1.5*labelSize[1])), (left + round(1.5*labelSize[0]), top + baseLine), (241, 113, 23), cv.FILLED)\n",
    "    cv.putText(frame, label, (left, top), cv.FONT_HERSHEY_DUPLEX, scale, (0,0,0), 2)\n",
    "\n",
    "    # Resize the mask, threshold, color and apply it on the image\n",
    "    classMask = cv.resize(classMask, (right - left + 1, bottom - top + 1))\n",
    "    mask = (classMask > maskThreshold)\n",
    "    roi = frame[top:bottom+1, left:right+1][mask]\n",
    "\n",
    "    # color = colors[classId%len(colors)]\n",
    "    # Comment the above line and uncomment the two lines below to generate different instance colors\n",
    "    colorIndex = random.randint(0, len(colors)-1)\n",
    "    color = colors[colorIndex]\n",
    "\n",
    "    frame[top:bottom+1, left:right+1][mask] = ([0.3*color[0], 0.3*color[1], 0.3*color[2]] + 0.7 * roi).astype(np.uint8)\n",
    "\n",
    "    # Draw the contours on the image\n",
    "    mask = mask.astype(np.uint8)\n",
    "    contours, hierarchy = cv.findContours(mask,cv.RETR_TREE,cv.CHAIN_APPROX_SIMPLE)\n",
    "    cv.drawContours(frame[top:bottom+1, left:right+1], contours, -1, color, 2, cv.LINE_8, hierarchy, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For each frame, extract the bounding box and mask for each detected object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess(boxes, masks):\n",
    "    # Output size of masks is NxCxHxW where\n",
    "    # N - number of detected boxes\n",
    "    # C - number of classes (excluding background)\n",
    "    # HxW - segmentation shape\n",
    "    numClasses = masks.shape[1]\n",
    "    numDetections = boxes.shape[2]\n",
    "\n",
    "    frameH = frame.shape[0]\n",
    "    frameW = frame.shape[1]\n",
    "\n",
    "    for i in range(numDetections):\n",
    "        box = boxes[0, 0, i]\n",
    "        mask = masks[i]\n",
    "        score = box[2]\n",
    "        if score > confThreshold:\n",
    "            classId = int(box[1])\n",
    "            \n",
    "            # Extract the bounding box\n",
    "            left = int(frameW * box[3])\n",
    "            top = int(frameH * box[4])\n",
    "            right = int(frameW * box[5])\n",
    "            bottom = int(frameH * box[6])\n",
    "            \n",
    "            left = max(0, min(left, frameW - 1))\n",
    "            top = max(0, min(top, frameH - 1))\n",
    "            right = max(0, min(right, frameW - 1))\n",
    "            bottom = max(0, min(bottom, frameH - 1))\n",
    "            \n",
    "            # Extract the mask for the object\n",
    "            classMask = mask[classId]\n",
    "\n",
    "            # Draw bounding box, colorize and show the mask on the image\n",
    "            drawBox(frame, classId, score, left, top, right, bottom, classMask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load names of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "classesFile = \"data/mscoco_labels.names\"\n",
    "classes = None\n",
    "with open(classesFile, 'rt') as f:\n",
    "   classes = f.read().rstrip('\\n').split('\\n')\n",
    "colorsFile = \"data/colors.txt\";\n",
    "with open(colorsFile, 'rt') as f:\n",
    "    colorsStr = f.read().rstrip('\\n').split('\\n')\n",
    "colors = [] #[0,0,0]\n",
    "for i in range(len(colorsStr)):\n",
    "    rgb = colorsStr[i].split(' ')\n",
    "    color = np.array([float(rgb[0]), float(rgb[1]), float(rgb[2])])\n",
    "    colors.append(color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the textGraph and weight files for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "textGraph = \"Models/mask_rcnn_inception_v2_coco_2018_01_28.pbtxt\"\n",
    "modelWeights = \"Models/mask_rcnn_inception_v2_coco_2018_01_28/frozen_inference_graph.pb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = cv.dnn.readNetFromTensorflow(modelWeights, textGraph);\n",
    "net.setPreferableBackend(cv.dnn.DNN_BACKEND_OPENCV)\n",
    "net.setPreferableTarget(cv.dnn.DNN_TARGET_CPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = cv.imread(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1080, 1924, 3)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a 4D blob from a frame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob = cv.dnn.blobFromImage(frame, swapRB=True, crop=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the input to the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.setInput(blob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the forward pass to get output from the output layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes, masks = net.forward(['detection_out_final', 'detection_masks'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the bounding box and mask for each of the detected objects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "postprocess(boxes, masks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Put efficiency information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "t, _ = net.getPerfProfile()\n",
    "label = 'Inference time for a frame : %0.0f ms' % abs(t * 1000.0 / cv.getTickFrequency())\n",
    "im2 = cv.putText(frame, label, (0, 25), cv.FONT_HERSHEY_DUPLEX, 1, (0, 0, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "winName = 'Mask-RCNN Object detection and Segmentation in OpenCV'\n",
    "cv.namedWindow(winName, cv.WINDOW_NORMAL)\n",
    "cv.imshow(winName, frame)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
